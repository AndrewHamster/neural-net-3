{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + math.exp(-x))\n",
    "@np.vectorize\n",
    "def sigmoidGradient(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test if numerical gradient is somewhere near computed one\n",
    "def numerical_grad():\n",
    "    def J_func(theta):\n",
    "        return compute_cost(X, y, theta)[0]\n",
    "    numgrad = np.zeros_like(weights)\n",
    "    perturb = np.zeros_like(weights)\n",
    "    e = 0.0001\n",
    "    for p in range(perturb.size):\n",
    "        perturb[p] = e\n",
    "        loss1 = J_func(weights - perturb)\n",
    "        loss2 = J_func(weights + perturb)\n",
    "        numgrad[p] = (loss2 - loss1) / (2 * e)\n",
    "        perturb[p] = 0\n",
    "    return numgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork3:\n",
    "    def __init__(self, input_layer_size, hidden_layer_size, output_layer_size):\n",
    "        self.input_layer_size = input_layer_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.output_layer_size = output_layer_size\n",
    "        self.theta1_size = (hidden_layer_size, input_layer_size + 1)\n",
    "        self.theta2_size = (output_layer_size, hidden_layer_size + 1)\n",
    "    \n",
    "    def train(self, X, y, iterations, learning_rate):\n",
    "        self._init_weights()\n",
    "        self.errors, self.weights = self._gradient_descent(X, y, self.weights, iterations=iterations, learning_rate=learning_rate)\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        Theta1 = np.random.random_sample(self.theta1_size)\n",
    "        Theta2 = np.random.random_sample(self.theta2_size)\n",
    "        self.weights = np.r_[Theta1.reshape(Theta1.size, 1), Theta2.reshape(Theta2.size, 1)].squeeze()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        m = X.shape[0]\n",
    "        #unfold weights\n",
    "        weights_counts = (self.theta1_size[0] * self.theta1_size[1], self.theta2_size[0] * self.theta2_size[1])\n",
    "        Theta1 = self.weights[:weights_counts[0]].reshape(self.theta1_size)\n",
    "        Theta2 = self.weights[weights_counts[0]:].reshape(self.theta2_size)\n",
    "        #forward propagation\n",
    "        a1 = np.hstack((np.ones((m, 1)), X))\n",
    "        z2 = a1.dot(Theta1.T)\n",
    "        a2 = np.hstack((np.ones((m, 1)), sigmoid(z2)))\n",
    "        z3 = a2.dot(Theta2.T)\n",
    "        h = sigmoid(z3)\n",
    "        return h\n",
    "    \n",
    "    def _compute_cost(self, X, y, weights):\n",
    "        #number of samples\n",
    "        m = X.shape[0]\n",
    "        #unfold weights\n",
    "        weights_counts = (self.theta1_size[0] * self.theta1_size[1], self.theta2_size[0] * self.theta2_size[1])\n",
    "        Theta1 = weights[:weights_counts[0]].reshape(self.theta1_size)\n",
    "        Theta2 = weights[weights_counts[0]:].reshape(self.theta2_size)\n",
    "        #forward propagation\n",
    "        a1 = np.hstack((np.ones((m, 1)), X))\n",
    "        z2 = a1.dot(Theta1.T)\n",
    "        a2 = np.hstack((np.ones((m, 1)), sigmoid(z2)))\n",
    "        z3 = a2.dot(Theta2.T)\n",
    "        h = sigmoid(z3)\n",
    "        #accumulator for error\n",
    "        s = 0\n",
    "        #accumulators for gradient\n",
    "        DELTA1 = np.zeros_like(Theta1)\n",
    "        DELTA2 = np.zeros_like(Theta2)\n",
    "        #todo vectorize (tbh, it's going to be extremely hard)\n",
    "        for i in range(m):\n",
    "            #hella long T.T\n",
    "            s = s - y[i].reshape(1, y[i].size).dot(np.vectorize(math.log)(h[i].reshape(1, h[i].size).T)) - (1 - y[i]).reshape(1, y[i].size).dot(np.vectorize(math.log)((1 - h[i]).reshape(1, h[i].size).T))\n",
    "            #backpropagation\n",
    "            d3 = (h[i] - y[i]).T.reshape(self.output_layer_size, 1)\n",
    "            part1 = Theta2.T.dot(d3)\n",
    "            part2 = sigmoidGradient(np.c_[np.zeros((1, 1)), z2[i].reshape(1, z2[i].size)]).T\n",
    "            d2 = (part1*part2)[1:,]\n",
    "            DELTA1 += d2.dot(a1[i].reshape(1, a1[i].size))\n",
    "            DELTA2 += d3.dot(a2[i].reshape(1, a2[i].size))\n",
    "        #values to return\n",
    "        J = float(s / m)\n",
    "        Theta1_grad = DELTA1 / m\n",
    "        Theta2_grad = DELTA2 / m\n",
    "        #todo add regularization\n",
    "        #fold weights\n",
    "        weights_grad = np.r_[Theta1_grad.reshape(Theta1_grad.size, 1), Theta2_grad.reshape(Theta2_grad.size, 1)].squeeze()\n",
    "        return (J, weights_grad)\n",
    "    \n",
    "    def _gradient_descent(self, X, y, weights, iterations=5000, learning_rate=1):\n",
    "        errors = []\n",
    "        for i in range(iterations):\n",
    "            start = datetime.datetime.now()\n",
    "            J, grad = self._compute_cost(X, y, weights)\n",
    "            errors.append(J)\n",
    "            weights = weights - learning_rate * grad\n",
    "            end = datetime.datetime.now()\n",
    "            print(end - start, ' per iteration', end='\\r')\n",
    "        return (errors, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mnist import MNIST\n",
    "mndata = MNIST(os.getcwd() + '/python-mnist/data')\n",
    "images, labels = mndata.load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns (inputs, labels)\n",
    "def load_data():\n",
    "    m_images = np.array(images).reshape(60000, 28*28) / 255\n",
    "    m_labels = np.zeros((60000, 10))\n",
    "    for i in range(len(labels)):\n",
    "        m_labels[i,labels[i]] = 1\n",
    "    ids = np.random.randint(0, high=60000, size=5000)\n",
    "    m_X = np.zeros((5000, 28*28))\n",
    "    m_y = np.zeros((5000, 10))\n",
    "    for i in range(5000):\n",
    "        m_X[i] = m_images[ids[i]]\n",
    "        m_y[i] = m_labels[ids[i]]\n",
    "    return (m_X, m_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NeuralNetwork3(28*28, 25, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:05.901552  per iteration\r"
     ]
    }
   ],
   "source": [
    "net.train(X, y, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04556521,  0.02210385,  0.08861638,  0.1747068 ,  0.10988941,\n",
       "         0.1129123 ,  0.14615729,  0.18670378,  0.15773331,  0.11996575]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict(X[13].reshape(1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
